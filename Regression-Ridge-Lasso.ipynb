{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of bias variance is super important to understand why ridge regression is an improvement over regular linear regression.\n",
    "\n",
    "Bias is related to model performance on training data. If a model overfits on training data, then it has low bias, whereas if a model is not a good fit for a dataset, it has high bias.\n",
    "\n",
    "When a model fits different testing sets with similar error sum range then it has low variance, when it fits with varying errors, then it's called high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multivariate regression is when you have multiple output variables to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Ridge Regression for layman\n",
    "https://towardsdatascience.com/ridge-regression-for-better-usage-2f19b3a202db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The alpha parameter is used to penalize the cofficients more and tune them to 0 which is the OLS behaviour, but a balance is required here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge does not get the coefficients to zero, just shrinks them, on the other hand lasso does remove unwanted variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/30456/geometric-interpretation-of-penalized-linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LASSO\n",
    "Lasso regularization can cut down the coefficients to zero. So it's better for feature selection. \n",
    "https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images generally associated of a circle with ridge and a diamond with lasso come from the equations.\n",
    "\n",
    "Lasso looks like |p1| + |p2| <= t which essentially maps to a diamond like shape \n",
    "Ridge looks like p1^2 + p2^2 <= c which essentially maps to a circle like shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
